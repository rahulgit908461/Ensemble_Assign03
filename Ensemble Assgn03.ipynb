{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3c03549a-52e6-49d9-bf2c-8ad47dbcde6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q1. What is Random Forest Regressor?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0d328e69-0dce-45bc-985f-45bd83469efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Random Forest Regression is a supervised learning algorithm that uses ensemble learning method for regression. \n",
    "#Ensemble learning method is a technique that combines predictions from multiple machine learning algorithms to \n",
    "#make a more accurate prediction than a single model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2f3a3e84-4bc1-43b8-9f54-de38c62def3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q2. How does Random Forest Regressor reduce the risk of overfitting?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2e7e15fc-d224-49e5-9cb9-e21436eaa861",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instead of relying on one decision tree, the random forest takes the prediction from each tree and based on the\n",
    "#majority votes of predictions, and it predicts the final output. The greater number of trees in the forest leads\n",
    "#to higher accuracy and prevents the problem of overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "37063eed-fa97-4295-b5d1-f928e45fdcc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q3. How does Random Forest Regressor aggregate the predictions of multiple decision trees?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "911d8d78-0dfd-42fa-863c-610bcb8ea8e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The Random Forest Algorithm combines the output of multiple (randomly created) Decision Trees to generate the final\n",
    "#output. This process of combining the output of multiple individual models (also known as weak learners) is called\n",
    "#Ensemble Learning.\n",
    "#allowing each individual tree to randomly sample from the dataset with replacement, resulting in different trees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7c0db83e-3ce1-485c-a5b6-bbd787cfd304",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q4. What are the hyperparameters of Random Forest Regressor?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "14f4b28b-93e8-4a7b-a835-17af1e1eb53c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#In random forest, the hyperparameters are the number of trees, number of features and the type of trees \n",
    "#(such as GBM or M5). The number of features is important and should be tuned. In this case, random forest is useful \n",
    "#because it automatically tunes the number of features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8def21e2-1177-465b-8d30-3073e1a35f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q5. What is the difference between Random Forest Regressor and Decision Tree Regressor?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7c1bd82c-1f92-4ee8-a25e-2359a7c9d804",
   "metadata": {},
   "outputs": [],
   "source": [
    "#A decision tree combines some decisions, whereas a random forest combines several decision trees. Thus, \n",
    "#it is a long process, yet slow. Whereas, a decision tree is fast and operates easily on large data sets, especially\n",
    "#the linear one. The random forest model needs rigorous training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "05fdc6e0-7a3c-4903-873a-5939ddd57e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q6. What are the advantages and disadvantages of Random Forest Regressor?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8133ceee-802e-4670-8575-ee37a7760d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Advantages of random forest\n",
    "#It can perform both regression and classification tasks.\n",
    "#A random forest produces good predictions that can be understood easily.\n",
    "#It can handle large datasets efficiently.\n",
    "#The random forest algorithm provides a higher level of accuracy in predicting outcomes over the decision tree\n",
    "#algorithm.\n",
    "#D-Advantages\n",
    "#The main limitation of random forest is that a large number of trees can make the algorithm too slow and \n",
    "#ineffective for real-time predictions. In general, these algorithms are fast to train, but quite slow to create \n",
    "#predictions once they are trained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1569a1bc-36e6-479e-9113-09b705b0a653",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q7. What is the output of Random Forest Regressor?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8de65ba3-0d7d-477c-b536-b11c2fbef468",
   "metadata": {},
   "outputs": [],
   "source": [
    "#For classification tasks, the output of the random forest is the class selected by most trees. For regression \n",
    "#tasks, the mean or average prediction of the individual trees is returned. Random decision forests correct for \n",
    "#decision trees' habit of overfitting to their training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f56fe09b-e78c-4b78-89a1-f94ea66b29ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q8. Can Random Forest Regressor be used for classification tasks?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3562944c-bfc1-4fc4-9843-bda1b3b90542",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Random Forest is a popular machine learning algorithm used for classification and regression tasks due to its \n",
    "#high accuracy, robustness, feature importance, versatility, and scalability. Random Forest reduces overfitting \n",
    "#by averaging multiple decision trees and is less sensitive to noise and outliers in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "def4ae5e-0017-4bf6-8c23-51503f7fb563",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Good"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb1103d3-768a-4bd0-b0a8-bbb082cebea3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "641c9018-a895-47f8-9e91-7708c9827fc1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e9cb904-6e7b-40f7-9337-5c0bb10a72c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b29112e-bdc2-42f3-a407-601765043367",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f618e516-85af-42e1-bfc1-1161e96375a5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
